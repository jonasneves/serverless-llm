# ===========================================
# Serverless LLM Configuration
# ===========================================
# Copy this file to .env and fill in your values

# Hugging Face (for gated models)
# HF_TOKEN=your_huggingface_token

# ===========================================
# Cloudflare Tunnel Tokens
# ===========================================
# Create tunnels at: https://one.dash.cloudflare.com/ > Access > Tunnels

# CLOUDFLARE_TUNNEL_TOKEN_CHAT=your_token
# CLOUDFLARE_TUNNEL_TOKEN_QWEN=your_token
# CLOUDFLARE_TUNNEL_TOKEN_PHI=your_token
# CLOUDFLARE_TUNNEL_TOKEN_LLAMA=your_token
# CLOUDFLARE_TUNNEL_TOKEN_MISTRAL=your_token
# CLOUDFLARE_TUNNEL_TOKEN_GEMMA=your_token
# CLOUDFLARE_TUNNEL_TOKEN_R1QWEN=your_token
# CLOUDFLARE_TUNNEL_TOKEN_RNJ=your_token

# ===========================================
# Model API URLs (for chat interface)
# ===========================================
# These are the public URLs exposed via Cloudflare Tunnels

# BASE_DOMAIN=your-domain.com
# QWEN_API_URL=https://qwen.your-domain.com
# PHI_API_URL=https://phi.your-domain.com
# LLAMA_API_URL=https://llama.your-domain.com
# MISTRAL_API_URL=https://mistral.your-domain.com
# GEMMA_API_URL=https://gemma.your-domain.com
# R1QWEN_API_URL=https://r1qwen.your-domain.com
# RNJ_API_URL=https://rnj.your-domain.com

# ===========================================
# GitHub Tokens
# ===========================================

# OPTIONAL: GitHub Models token for Discussion/Agents modes
# Default uses free quota, or configure your own at:
# https://github.com/settings/personal-access-tokens/new (user_models:read permission)
# GH_MODELS_TOKEN=your_github_token

# For auto-restart functionality (needs workflow dispatch permission)
# WORKFLOW_PAT=your_pat_for_auto_restart
