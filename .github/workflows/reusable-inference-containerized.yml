name: Reusable Containerized Inference

on:
  workflow_call:
    inputs:
      model_name:
        required: true
        type: string
      model_dir:
        required: true
        type: string
      model_repo:
        required: true
        type: string
      model_file:
        required: true
        type: string
      cache_key_prefix:
        required: true
        type: string
      tunnel_secret_name:
        required: true
        type: string
      restart_event_type:
        required: true
        type: string
      workflow_file:
        required: true
        type: string
      duration_hours:
        type: string
        default: '5'
      auto_restart:
        type: boolean
        default: true
      instances:
        type: string
        default: '1'
      port:
        type: string
        default: '8000'
    secrets:
      hf_token:
        required: true
      tunnel_token:
        required: true
      workflow_pat:
        required: true

jobs:
  inference:
    name: ${{ inputs.model_name }} #${{ matrix.instance }}
    runs-on: ubuntu-latest
    timeout-minutes: 350
    permissions:
      actions: write
      contents: read
      packages: read
    strategy:
      matrix:
        instance: ${{ fromJson(inputs.instances == '3' && '[1,2,3]' || inputs.instances == '2' && '[1,2]' || '[1]') }}
      fail-fast: false

    steps:
      - name: Find previous workflow
        id: find_previous
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          API_RESPONSE=$(curl -s \
            -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${{ inputs.workflow_file }}/runs?status=in_progress")

          PREVIOUS_RUN_ID=$(echo "$API_RESPONSE" | jq -r ".workflow_runs[] | select(.id < ${{ github.run_id }}) | .id" | head -1)

          if [ -n "$PREVIOUS_RUN_ID" ] && [ "$PREVIOUS_RUN_ID" != "null" ]; then
            echo "previous_run_id=$PREVIOUS_RUN_ID" >> $GITHUB_OUTPUT
          else
            echo "previous_run_id=" >> $GITHUB_OUTPUT
          fi

      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build cloudflared
        uses: docker/build-push-action@v5
        with:
          context: ./docker/cloudflared
          tags: cloudflared:latest
          load: true
          cache-from: type=gha,scope=cloudflared
          cache-to: type=gha,mode=max,scope=cloudflared

      - name: Pull inference image from GHCR
        id: pull
        continue-on-error: true
        run: |
          IMAGE="ghcr.io/${{ github.repository_owner }}/serverless-llm/${{ inputs.model_dir }}:latest"
          echo "Attempting to pull $IMAGE"

          if docker pull "$IMAGE"; then
            docker tag "$IMAGE" "${{ inputs.model_name }}-inference:latest"
            echo "pulled=true" >> $GITHUB_OUTPUT
            echo "Successfully pulled image from GHCR"
          else
            echo "pulled=false" >> $GITHUB_OUTPUT
            echo "Failed to pull image from GHCR, will build locally"
          fi

      - name: Build inference server (fallback)
        if: steps.pull.outputs.pulled != 'true'
        uses: docker/build-push-action@v5
        with:
          context: ./app
          file: ./app/${{ inputs.model_dir }}/Dockerfile
          tags: ${{ inputs.model_name }}-inference:latest
          load: true
          cache-from: type=gha,scope=${{ inputs.cache_key_prefix }}
          cache-to: type=gha,mode=max,scope=${{ inputs.cache_key_prefix }}
          build-args: |
            MODEL_REPO=${{ inputs.model_repo }}
            MODEL_FILE=${{ inputs.model_file }}

      - name: Create network
        run: docker network create inference-network

      - name: Start inference server
        env:
          MODEL_REPO: ${{ inputs.model_repo }}
          MODEL_FILE: ${{ inputs.model_file }}
          PORT: ${{ inputs.port }}
          HF_TOKEN: ${{ secrets.hf_token }}
        run: |
          docker run -d \
            --name inference-server \
            --network inference-network \
            -p ${{ inputs.port }}:${{ inputs.port }} \
            -e MODEL_REPO="$MODEL_REPO" \
            -e MODEL_FILE="$MODEL_FILE" \
            -e PORT="$PORT" \
            -e HF_TOKEN="$HF_TOKEN" \
            -e HF_HOME=/app/.cache/huggingface \
            -v $HOME/.cache/huggingface:/app/.cache/huggingface \
            ${{ inputs.model_name }}-inference:latest

          # Health check
          HEALTHY=false
          for i in {1..30}; do
            if ! docker ps | grep -q inference-server; then
              echo "Container stopped"
              docker logs inference-server
              exit 1
            fi

            RESPONSE=$(curl -s http://localhost:${{ inputs.port }}/health || echo "")
            if echo "$RESPONSE" | grep -q "healthy"; then
              echo "Server ready"
              HEALTHY=true
              break
            fi

            echo "Waiting... ($i/30)"
            sleep 10
          done

          if [ "$HEALTHY" = "false" ]; then
            docker logs inference-server
            exit 1
          fi

      - name: Start cloudflared
        env:
          TUNNEL_TOKEN: ${{ secrets.tunnel_token }}
        run: |
          docker run -d \
            --name cloudflared \
            --network host \
            cloudflared:latest \
            tunnel --no-autoupdate run --token "$TUNNEL_TOKEN"

          sleep 10
          docker logs cloudflared | head -20

      - name: Cancel previous workflow
        if: steps.find_previous.outputs.previous_run_id != ''
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          curl -s -X POST \
            -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ steps.find_previous.outputs.previous_run_id }}/cancel"

          echo "Graceful handoff: waiting 60s for previous instance to shutdown"
          sleep 60

      - name: Monitor
        env:
          DURATION_HOURS: ${{ inputs.duration_hours }}
          AUTO_RESTART: ${{ inputs.auto_restart }}
          PORT: ${{ inputs.port }}
        run: |
          cleanup() {
            docker stop inference-server cloudflared 2>/dev/null || true
            docker rm inference-server cloudflared 2>/dev/null || true
            docker network rm inference-network 2>/dev/null || true
            exit 0
          }
          trap cleanup SIGTERM SIGINT

          DURATION=$((DURATION_HOURS * 3600))
          RESTART_THRESHOLD=$((DURATION - 360))
          START_TIME=$(date +%s)
          RESTART_TRIGGERED=false

          while true; do
            ELAPSED=$(($(date +%s) - START_TIME))
            REMAINING=$((DURATION - ELAPSED))

            SERVER_STATUS=$(docker inspect -f '{{.State.Status}}' inference-server 2>/dev/null || echo "stopped")
            TUNNEL_STATUS=$(docker inspect -f '{{.State.Status}}' cloudflared 2>/dev/null || echo "stopped")

            printf "[%s] Server: %s | Tunnel: %s | %dm elapsed | %dm remaining\n" \
              "$(date '+%H:%M:%S')" "$SERVER_STATUS" "$TUNNEL_STATUS" "$((ELAPSED/60))" "$((REMAINING/60))"

            [ "$SERVER_STATUS" != "running" ] && docker start inference-server
            [ "$TUNNEL_STATUS" != "running" ] && docker start cloudflared

            # Auto-restart
            if [ "$ELAPSED" -gt "$RESTART_THRESHOLD" ] && [ "$RESTART_TRIGGERED" = "false" ] && [ "${{ matrix.instance }}" = "1" ]; then
              if [ "$AUTO_RESTART" = "true" ]; then
                PAT="${{ secrets.workflow_pat }}"
                if [ -n "$PAT" ]; then
                  curl -sX POST \
                    -H "Authorization: Bearer $PAT" \
                    https://api.github.com/repos/${{ github.repository }}/dispatches \
                    -d "{\"event_type\":\"${{ inputs.restart_event_type }}\",\"client_payload\":{\"duration_hours\":\"$DURATION_HOURS\",\"auto_restart\":$AUTO_RESTART,\"instances\":\"${{ inputs.instances }}\"}}"

                  echo "Waiting 90s for new instance to start"
                  sleep 90
                fi
                RESTART_TRIGGERED=true
              fi
            fi

            [ $ELAPSED -gt $DURATION ] && break
            sleep 30
          done

          cleanup

      - name: Show logs on failure
        if: failure()
        run: |
          docker logs inference-server 2>&1 | tail -100
          docker logs cloudflared 2>&1 | tail -50
