name: Reusable Containerized Inference

on:
  workflow_call:
    inputs:
      model_name:
        required: true
        type: string
      model_dir:
        required: true
        type: string
      model_repo:
        required: true
        type: string
      model_file:
        required: true
        type: string
      cache_key_prefix:
        required: true
        type: string
      restart_event_type:
        required: true
        type: string
      workflow_file:
        required: true
        type: string
      duration_hours:
        type: string
        default: '5'
      auto_restart:
        type: boolean
        default: true
      instances:
        type: string
        default: '1'
      port:
        type: string
        default: '8000'
      n_ctx:
        type: string
        required: false
        description: 'Context window size (leave empty to use model default)'
      n_threads:
        type: string
        required: false
        description: 'Number of CPU threads (leave empty to use model default)'
      n_batch:
        type: string
        required: false
        description: 'Batch size for processing (leave empty to use model default)'
      max_concurrent:
        type: string
        required: false
        description: 'Maximum concurrent requests per instance (leave empty to use model default)'
    secrets:
      hf_token:
        required: true
      tunnel_token:
        required: false
        description: 'Tunnel token (optional if tunnels_json is provided)'
      tunnels_json:
        required: false
        description: 'tunnels.json content as JSON string (alternative to tunnel_token)'
      workflow_pat:
        required: true

jobs:
  inference:
    name: ${{ inputs.model_name }} #${{ matrix.instance }}
    runs-on: ubuntu-24.04-arm  # ARM64 runners for ARM-optimized inference
    timeout-minutes: 350
    permissions:
      actions: write
      contents: read
      packages: read
    strategy:
      matrix:
        instance: ${{ fromJson(inputs.instances == '3' && '[1,2,3]' || inputs.instances == '2' && '[1,2]' || '[1]') }}
      fail-fast: false

    steps:
      - name: Find previous workflow
        id: find_previous
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          API_RESPONSE=$(curl -s \
            -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${{ inputs.workflow_file }}/runs?status=in_progress")

          PREVIOUS_RUN_ID=$(echo "$API_RESPONSE" | jq -r ".workflow_runs[] | select(.id < ${{ github.run_id }}) | .id" | head -1)

          if [ -n "$PREVIOUS_RUN_ID" ] && [ "$PREVIOUS_RUN_ID" != "null" ]; then
            echo "previous_run_id=$PREVIOUS_RUN_ID" >> $GITHUB_OUTPUT
          else
            echo "previous_run_id=" >> $GITHUB_OUTPUT
          fi

      - uses: actions/checkout@v4

      - name: Move Docker data to /mnt
        run: |
          echo "=== Available storage ==="
          df -h / /mnt
          
          # Stop Docker
          sudo systemctl stop docker
          
          # Move Docker data directory to /mnt (has ~66GB free)
          sudo mkdir -p /mnt/docker
          sudo rsync -aP /var/lib/docker/ /mnt/docker/ || true
          sudo rm -rf /var/lib/docker
          sudo ln -s /mnt/docker /var/lib/docker
          
          # Restart Docker
          sudo systemctl start docker
          
          echo "✓ Docker configured to use /mnt"

      - name: Setup environment (parallel)
        run: |
          # Run swap setup in background
          (
            sudo fallocate -l 16G /swapfile
            sudo chmod 600 /swapfile
            sudo mkswap /swapfile
            sudo swapon /swapfile
            sudo sysctl -w vm.swappiness=60 > /dev/null
            sudo sysctl -w vm.vfs_cache_pressure=50 > /dev/null
            echo "✓ Swap enabled: 16GB"
          ) &
          SWAP_PID=$!
          
          # Setup cache directory in background
          (
            sudo mkdir -p /mnt/huggingface-cache
            sudo chown -R 10000:10000 /mnt/huggingface-cache
            echo "✓ Cache directory ready"
          ) &
          CACHE_PID=$!
          
          # Wait for both
          wait $SWAP_PID $CACHE_PID
          echo "✓ Environment setup complete"

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull images and setup network (parallel)
        run: |
          # Pull both images in parallel
          echo "Pulling images in parallel..."
          
          docker pull "ghcr.io/${{ github.repository_owner }}/serverless-llm/cloudflared:latest" &
          CLOUDFLARED_PID=$!
          
          docker pull "ghcr.io/${{ github.repository_owner }}/serverless-llm/${{ inputs.model_dir }}:latest" &
          INFERENCE_PID=$!
          
          # Create network while images are pulling
          docker network create inference-network || true
          echo "✓ Network created"
          
          # Wait for both pulls to complete
          echo "Waiting for image pulls..."
          wait $CLOUDFLARED_PID
          CLOUDFLARED_EXIT=$?
          wait $INFERENCE_PID
          INFERENCE_EXIT=$?
          
          # Check results
          if [ $CLOUDFLARED_EXIT -ne 0 ]; then
            echo "❌ Failed to pull cloudflared image"
            exit 1
          fi
          
          if [ $INFERENCE_EXIT -ne 0 ]; then
            echo "❌ Failed to pull inference image"
            exit 1
          fi
          
          # Tag images
          docker tag "ghcr.io/${{ github.repository_owner }}/serverless-llm/cloudflared:latest" "cloudflared:latest"
          docker tag "ghcr.io/${{ github.repository_owner }}/serverless-llm/${{ inputs.model_dir }}:latest" "${{ inputs.model_name }}-inference:latest"
          
          echo "✓ All images pulled and tagged"

      - name: Start inference server
        env:
          MODEL_REPO: ${{ inputs.model_repo }}
          MODEL_FILE: ${{ inputs.model_file }}
          PORT: ${{ inputs.port }}
          HF_TOKEN: ${{ secrets.hf_token }}
          N_CTX: ${{ inputs.n_ctx }}
          N_THREADS: ${{ inputs.n_threads }}
          N_BATCH: ${{ inputs.n_batch }}
          MAX_CONCURRENT: ${{ inputs.max_concurrent }}
        run: |
          # Build docker run command with optional parameters
          CMD="docker run -d \
            --name inference-server \
            --network inference-network \
            -p ${{ inputs.port }}:${{ inputs.port }} \
            -e MODEL_REPO=\"$MODEL_REPO\" \
            -e MODEL_FILE=\"$MODEL_FILE\" \
            -e PORT=\"$PORT\" \
            -e HF_TOKEN=\"$HF_TOKEN\" \
            -e HF_HOME=/app/.cache/huggingface \
            -e INSTANCE_ID=\"${{ matrix.instance }}\" \
            -e GITHUB_SHA=\"${{ github.sha }}\""

          # Add N_CTX if provided
          if [ -n "$N_CTX" ]; then
            CMD="$CMD -e N_CTX=\"$N_CTX\""
          fi

          # Add N_THREADS if provided
          if [ -n "$N_THREADS" ]; then
            CMD="$CMD -e N_THREADS=\"$N_THREADS\""
          fi

          # Add N_BATCH if provided
          if [ -n "$N_BATCH" ]; then
            CMD="$CMD -e N_BATCH=\"$N_BATCH\""
          fi

          # Add MAX_CONCURRENT if provided
          if [ -n "$MAX_CONCURRENT" ]; then
            CMD="$CMD -e MAX_CONCURRENT=\"$MAX_CONCURRENT\""
          fi

          CMD="$CMD -v /mnt/huggingface-cache:/app/.cache/huggingface \
            ${{ inputs.model_name }}-inference:latest"

          echo "Starting inference server with command:"
          echo "$CMD"
          eval $CMD

          # Health check
          HEALTHY=false
          for i in {1..30}; do
            if ! docker ps | grep -q inference-server; then
              echo "Container stopped unexpectedly"
              echo ""
              echo "=== Full container logs ==="
              docker logs inference-server 2>&1
              echo ""
              echo "=== Container exit code ==="
              docker inspect inference-server --format='{{.State.ExitCode}}'
              echo ""
              echo "=== Memory usage before crash ==="
              free -h
              exit 1
            fi

            RESPONSE=$(curl -s http://localhost:${{ inputs.port }}/health || echo "")
            if echo "$RESPONSE" | grep -q "healthy"; then
              echo "Server ready"
              HEALTHY=true
              break
            fi

            echo "Waiting... ($i/30)"
            sleep 10
          done

          if [ "$HEALTHY" = "false" ]; then
            docker logs inference-server
            exit 1
          fi

      - name: Get tunnel token
        id: tunnel_token
        env:
          TUNNELS_JSON: ${{ secrets.tunnels_json }}
          TUNNEL_TOKEN_SECRET: ${{ secrets.tunnel_token }}
        run: |
          # Try unified script first (reads from TUNNELS_JSON env var automatically)
          TOKEN=$(python3 scripts/get_tunnel_token.py "${{ inputs.model_name }}" --silent 2>/dev/null) || true
          
          # Fallback to individual tunnel_token secret
          if [ -z "$TOKEN" ] && [ -n "$TUNNEL_TOKEN_SECRET" ]; then
            TOKEN="$TUNNEL_TOKEN_SECRET"
            echo "⚠️  Using tunnel_token secret (model not in tunnels.json)"
          fi
          
          if [ -n "$TOKEN" ]; then
            # Mask the token so it never appears in logs
            echo "::add-mask::$TOKEN"
            echo "token=$TOKEN" >> $GITHUB_OUTPUT
            echo "✓ Tunnel token configured for ${{ inputs.model_name }}"
          else
            echo "❌ Error: No tunnel token available for ${{ inputs.model_name }}"
            echo "   - Add model to tunnels.json and update TUNNELS_JSON secret, OR"
            echo "   - Provide tunnel_token secret for this workflow"
            exit 1
          fi

      - name: Start cloudflared
        env:
          TUNNEL_TOKEN: ${{ steps.tunnel_token.outputs.token }}
        run: |
          docker run -d \
            --name cloudflared \
            --network host \
            cloudflared:latest \
            tunnel --no-autoupdate run --token "$TUNNEL_TOKEN"

          sleep 10
          docker logs cloudflared | head -20

      - name: Cancel previous workflow
        if: steps.find_previous.outputs.previous_run_id != ''
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          curl -s -X POST \
            -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ steps.find_previous.outputs.previous_run_id }}/cancel"

          echo "Graceful handoff: waiting 60s for previous instance to shutdown"
          sleep 60

      - name: Monitor
        env:
          PORT: ${{ inputs.port }}
        run: |
          cleanup() {
            docker stop inference-server cloudflared 2>/dev/null || true
            docker rm inference-server cloudflared 2>/dev/null || true
            docker network rm inference-network 2>/dev/null || true
            exit 0
          }
          trap cleanup SIGTERM SIGINT

          # Get duration from inputs
          DURATION_HOURS="${{ inputs.duration_hours }}"
          DURATION=$((DURATION_HOURS * 3600))
          RESTART_THRESHOLD=$((DURATION - 360))
          START_TIME=$(date +%s)
          RESTART_TRIGGERED=false

          # Auto-restart defaults to true
          AUTO_RESTART="${{ inputs.auto_restart }}"
          if [ -z "$AUTO_RESTART" ]; then
            AUTO_RESTART="true"
          fi

          INSTANCES="${{ inputs.instances }}"
          N_CTX="${{ inputs.n_ctx }}"
          N_THREADS="${{ inputs.n_threads }}"
          N_BATCH="${{ inputs.n_batch }}"
          MAX_CONCURRENT="${{ inputs.max_concurrent }}"
          echo "Duration: ${DURATION_HOURS}h | Auto-restart: $AUTO_RESTART | Instances: $INSTANCES | n_ctx: $N_CTX"

          while true; do
            ELAPSED=$(($(date +%s) - START_TIME))
            REMAINING=$((DURATION - ELAPSED))

            SERVER_STATUS=$(docker inspect -f '{{.State.Status}}' inference-server 2>/dev/null || echo "stopped")
            TUNNEL_STATUS=$(docker inspect -f '{{.State.Status}}' cloudflared 2>/dev/null || echo "stopped")

            printf "[%s] Server: %s | Tunnel: %s | %dm elapsed | %dm remaining\n" \
              "$(date '+%H:%M:%S')" "$SERVER_STATUS" "$TUNNEL_STATUS" "$((ELAPSED/60))" "$((REMAINING/60))"

            [ "$SERVER_STATUS" != "running" ] && docker start inference-server
            [ "$TUNNEL_STATUS" != "running" ] && docker start cloudflared

            # Auto-restart (only from instance 1 to avoid multiple dispatches)
            if [ "$ELAPSED" -gt "$RESTART_THRESHOLD" ] && [ "$RESTART_TRIGGERED" = "false" ] && [ "${{ matrix.instance }}" = "1" ]; then
              if [ "$AUTO_RESTART" = "true" ]; then
                echo ""
                echo "=========================================="
                echo "Triggering restart workflow..."
                echo "=========================================="

                PAT="${{ secrets.workflow_pat }}"
                if [ -z "$PAT" ]; then
                  echo "ERROR: WORKFLOW_PAT secret is not set!"
                  echo "Auto-restart requires a Personal Access Token with 'repo' scope"
                  RESTART_TRIGGERED=true
                else
                  RESPONSE=$(curl -sX POST \
                    -H "Accept: application/vnd.github+json" \
                    -H "Authorization: Bearer $PAT" \
                    -H "X-GitHub-Api-Version: 2022-11-28" \
                    https://api.github.com/repos/${{ github.repository }}/dispatches \
                    -d "{\"event_type\":\"${{ inputs.restart_event_type }}\",\"client_payload\":{\"duration_hours\":\"$DURATION_HOURS\",\"auto_restart\":$([ \"$AUTO_RESTART\" = \"true\" ] && echo \"true\" || echo \"false\"),\"instances\":\"$INSTANCES\",\"n_ctx\":\"$N_CTX\",\"n_threads\":\"$N_THREADS\",\"n_batch\":\"$N_BATCH\",\"max_concurrent\":\"$MAX_CONCURRENT\"}}" \
                    -w "\nHTTP_STATUS:%{http_code}" 2>&1)

                  HTTP_CODE=$(echo "$RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
                  BODY=$(echo "$RESPONSE" | grep -v "HTTP_STATUS:")

                  if [ "$HTTP_CODE" = "204" ]; then
                    echo "SUCCESS: Restart triggered!"
                    echo "Waiting 90s for new instance to start..."
                    sleep 90
                  elif [ "$HTTP_CODE" = "401" ]; then
                    echo "ERROR: Authentication failed (401) - Check WORKFLOW_PAT"
                  elif [ "$HTTP_CODE" = "403" ]; then
                    echo "ERROR: Permission denied (403) - WORKFLOW_PAT needs 'repo' scope"
                  else
                    echo "ERROR: Failed to trigger restart (HTTP $HTTP_CODE)"
                    [ -n "$BODY" ] && echo "Response: $BODY"
                  fi

                  RESTART_TRIGGERED=true
                fi
              fi
            fi

            [ $ELAPSED -gt $DURATION ] && break
            sleep 30
          done

          cleanup

      - name: Show logs on failure
        if: failure()
        run: |
          docker logs inference-server 2>&1 | tail -100
          docker logs cloudflared 2>&1 | tail -50
