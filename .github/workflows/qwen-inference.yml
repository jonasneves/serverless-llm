name: Qwen 2.5-14B Inference Server

on:
  workflow_dispatch:
    inputs:
      duration_hours:
        description: 'How long to run (max 5.5 hours)'
        required: false
        default: '5.5'
        type: string
      auto_restart:
        description: 'Auto-restart before timeout'
        required: false
        default: true
        type: boolean

  repository_dispatch:
    types: [restart-qwen-inference]

jobs:
  inference:
    name: Qwen 2.5-14B Server
    runs-on: ubuntu-latest
    timeout-minutes: 350

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'app/qwen-inference/requirements.txt'

      - name: Install dependencies
        run: |
          pip install -r app/qwen-inference/requirements.txt

      - name: Cache Hugging Face models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: hf-qwen2.5-14b-${{ runner.os }}

      - name: Install cloudflared
        run: |
          curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared
          chmod +x cloudflared
          sudo mv cloudflared /usr/local/bin/

      - name: Start inference server
        env:
          MODEL_NAME: Qwen/Qwen2.5-14B-Instruct
          USE_4BIT: "true"
          PORT: "8000"
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd app/qwen-inference
          python inference_server.py &
          echo "Waiting for server to start..."
          sleep 30

          # Health check
          for i in {1..30}; do
            if curl -s http://localhost:8000/health | grep -q "healthy"; then
              echo "Server is healthy!"
              break
            fi
            echo "Waiting for server... attempt $i"
            sleep 10
          done

      - name: Start Cloudflare Tunnel
        env:
          CLOUDFLARE_TUNNEL_TOKEN: ${{ secrets.CLOUDFLARE_TUNNEL_TOKEN_QWEN }}
        run: |
          if [ -n "$CLOUDFLARE_TUNNEL_TOKEN" ]; then
            cloudflared tunnel --no-autoupdate run --token "$CLOUDFLARE_TUNNEL_TOKEN" &
            echo "Cloudflare tunnel started"
          else
            echo "No tunnel token provided, server only accessible locally"
          fi

      - name: Health monitoring loop
        env:
          DURATION_HOURS: ${{ inputs.duration_hours || '5.5' }}
          AUTO_RESTART: ${{ inputs.auto_restart }}
        run: |
          END_TIME=$(date -d "+${DURATION_HOURS} hours" +%s)
          RESTART_TIME=$(date -d "+${DURATION_HOURS} hours -5 minutes" +%s)

          echo "=== Qwen 2.5-14B Inference Server ==="
          echo "Server running on port 8000"
          echo "Will run until: $(date -d "@$END_TIME")"
          echo "======================================="

          while true; do
            CURRENT_TIME=$(date +%s)

            # Check if we need to restart
            if [ "$AUTO_RESTART" = "true" ] && [ $CURRENT_TIME -ge $RESTART_TIME ]; then
              echo "Approaching timeout, triggering restart..."
              curl -X POST \
                -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                -H "Accept: application/vnd.github.v3+json" \
                "https://api.github.com/repos/${{ github.repository }}/dispatches" \
                -d '{"event_type":"restart-qwen-inference"}'
              break
            fi

            # Check if time exceeded
            if [ $CURRENT_TIME -ge $END_TIME ]; then
              echo "Duration exceeded, shutting down..."
              break
            fi

            # Health check
            if curl -s http://localhost:8000/health | grep -q "healthy"; then
              echo "[$(date)] Server healthy - GPU: $(curl -s http://localhost:8000/health | jq -r '.gpu_available')"
            else
              echo "[$(date)] Server unhealthy, attempting restart..."
              cd app/qwen-inference
              pkill -f inference_server.py || true
              python inference_server.py &
              sleep 30
            fi

            sleep 30
          done
