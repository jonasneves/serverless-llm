name: Inference
run-name: "${{ github.event.client_payload.model || inputs.model }} \u2022 ${{ github.event.client_payload.duration_hours || inputs.duration_hours || '5' }}h \xD7 ${{ github.event.client_payload.instances || inputs.instances || '1' }}"
'on':
  workflow_dispatch:
    inputs:
      model:
        description: Model to run
        required: true
        type: choice
        options:
        - agentcpm
        - dasd
        - functiongemma
        - gemma
        - gptoss
        - lfm2
        - llama
        - mistral
        - nanbeige
        - phi
        - qwen
        - r1qwen
        - rnj
        - smollm3
      instances:
        description: Parallel instances (1-3)
        required: false
        default: '1'
        type: choice
        options:
        - '1'
        - '2'
        - '3'
      duration_hours:
        description: Duration (max 5.5 hours)
        required: false
        default: '5'
        type: string
      auto_restart:
        description: Auto-restart before timeout
        required: false
        default: true
        type: boolean
  repository_dispatch:
    types:
    - restart-inference
permissions:
  actions: write
  contents: read
  packages: read
jobs:
  lookup:
    name: Lookup model config
    runs-on: ubuntu-latest
    outputs:
      model_name: ${{ steps.config.outputs.model_name }}
      model_dir: ${{ steps.config.outputs.model_dir }}
      model_repo: ${{ steps.config.outputs.model_repo }}
      model_file: ${{ steps.config.outputs.model_file }}
      display_name: ${{ steps.config.outputs.display_name }}
    steps:
    - uses: actions/checkout@v4
    - name: Read model config
      id: config
      run: |
        MODEL="${{ github.event.client_payload.model || inputs.model }}"

        # Read config from Python (single source of truth)
        CONFIG=$(python3 config/models.py "$MODEL")
        if [ $? -ne 0 ]; then
          echo "Error: Model '$MODEL' not found in config/models.py"
          exit 1
        fi

        # Parse JSON output
        MODEL_DIR=$(echo "$CONFIG" | python3 -c "import sys,json; print(json.load(sys.stdin)['model_dir'])")
        MODEL_REPO=$(echo "$CONFIG" | python3 -c "import sys,json; print(json.load(sys.stdin)['model_repo'])")
        MODEL_FILE=$(echo "$CONFIG" | python3 -c "import sys,json; print(json.load(sys.stdin)['model_file'])")
        DISPLAY_NAME=$(echo "$CONFIG" | python3 -c "import sys,json; print(json.load(sys.stdin)['display_name'])")

        echo "model_name=$MODEL" >> $GITHUB_OUTPUT
        echo "model_dir=$MODEL_DIR" >> $GITHUB_OUTPUT
        echo "model_repo=$MODEL_REPO" >> $GITHUB_OUTPUT
        echo "model_file=$MODEL_FILE" >> $GITHUB_OUTPUT
        echo "display_name=$DISPLAY_NAME" >> $GITHUB_OUTPUT

        echo "Model: $DISPLAY_NAME"
        echo "Repo: $MODEL_REPO"
        echo "File: $MODEL_FILE"
  inference:
    name: ${{ needs.lookup.outputs.display_name }}
    needs: lookup
    uses: ./.github/workflows/reusable-inference-containerized.yml
    with:
      model_name: ${{ needs.lookup.outputs.model_name }}
      model_dir: ${{ needs.lookup.outputs.model_dir }}
      model_repo: ${{ needs.lookup.outputs.model_repo }}
      model_file: ${{ needs.lookup.outputs.model_file }}
      cache_key_prefix: gguf-${{ needs.lookup.outputs.model_name }}
      restart_event_type: restart-inference
      workflow_file: inference.yml
      duration_hours: ${{ github.event.client_payload.duration_hours || inputs.duration_hours || '5' }}
      auto_restart: ${{ (github.event.client_payload.auto_restart == true || github.event.client_payload.auto_restart == 'true')
        || (inputs.auto_restart == true || inputs.auto_restart == 'true' || inputs.auto_restart == '') }}
      instances: ${{ github.event.client_payload.instances || inputs.instances || '1' }}
    secrets:
      hf_token: ${{ secrets.HF_TOKEN }}
      tunnels_json: ${{ secrets.TUNNELS_JSON }}
      workflow_pat: ${{ secrets.WORKFLOW_PAT }}
