# ==============================================================================
# GitHub Actions Cache Audit
# ==============================================================================
# This workflow helps monitor and manage GitHub Actions cache usage.
# With the new larger cache limits (exceeding 10GB), this audit helps you:
# - Track current cache usage
# - Identify cache optimization opportunities
# - Clean up old or oversized caches
# ==============================================================================

name: Cache Audit

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'audit'
        type: choice
        options:
          - 'audit'
          - 'cleanup-old'
          - 'cleanup-oversized'
      days_old:
        description: 'For cleanup-old: Delete caches older than N days'
        required: false
        default: '30'
        type: string
      size_limit_gb:
        description: 'For cleanup-oversized: Delete caches larger than N GB'
        required: false
        default: '5'
        type: string
  schedule:
    # Run weekly audit on Sundays at midnight UTC
    - cron: '0 0 * * 0'

permissions:
  actions: write

jobs:
  cache-audit:
    runs-on: ubuntu-latest
    steps:
      - name: Get cache usage summary
        id: cache-usage
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "# ðŸ“Š GitHub Actions Cache Audit" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Repository Cache Usage" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Get cache usage
          USAGE=$(gh api repos/${{ github.repository }}/actions/cache/usage 2>/dev/null || echo '{"active_caches_size_in_bytes":0,"active_caches_count":0}')
          
          SIZE_BYTES=$(echo "$USAGE" | jq -r '.active_caches_size_in_bytes // 0')
          COUNT=$(echo "$USAGE" | jq -r '.active_caches_count // 0')
          
          # Convert to human-readable
          SIZE_MB=$(echo "scale=2; $SIZE_BYTES / 1048576" | bc)
          SIZE_GB=$(echo "scale=2; $SIZE_BYTES / 1073741824" | bc)
          
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Total Cache Size | ${SIZE_GB} GB (${SIZE_MB} MB) |" >> $GITHUB_STEP_SUMMARY
          echo "| Total Cache Count | ${COUNT} |" >> $GITHUB_STEP_SUMMARY
          echo "| Previous Limit | 10 GB |" >> $GITHUB_STEP_SUMMARY
          echo "| New Limit | Unlimited (via new architecture) |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check cache health
          echo "## Cache Health Assessment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Compare to old limit
          OLD_LIMIT_BYTES=10737418240
          USAGE_PERCENT=$(echo "scale=1; $SIZE_BYTES * 100 / $OLD_LIMIT_BYTES" | bc)
          
          if (( $(echo "$SIZE_BYTES > $OLD_LIMIT_BYTES" | bc -l) )); then
            echo "âœ… **Leveraging new larger cache limits!** You're using ${SIZE_GB} GB, which exceeds the previous 10 GB limit." >> $GITHUB_STEP_SUMMARY
          elif (( $(echo "$USAGE_PERCENT > 80" | bc -l) )); then
            echo "âš ï¸ **Near capacity:** ${USAGE_PERCENT}% of previous 10 GB limit used." >> $GITHUB_STEP_SUMMARY
            echo "Consider leveraging the new larger limits for additional caching." >> $GITHUB_STEP_SUMMARY
          else
            echo "âœ… **Cache usage healthy:** ${USAGE_PERCENT}% of previous limit used." >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Store for next steps
          echo "size_bytes=$SIZE_BYTES" >> $GITHUB_OUTPUT
          echo "count=$COUNT" >> $GITHUB_OUTPUT

      - name: List all caches
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "## All Caches" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Get all caches
          CACHES=$(gh api repos/${{ github.repository }}/actions/caches --paginate 2>/dev/null || echo '{"actions_caches":[]}')
          
          CACHE_COUNT=$(echo "$CACHES" | jq '.actions_caches | length')
          
          if [ "$CACHE_COUNT" -eq 0 ]; then
            echo "No caches found." >> $GITHUB_STEP_SUMMARY
          else
            echo "| Key | Size | Created | Last Accessed | Branch |" >> $GITHUB_STEP_SUMMARY
            echo "|-----|------|---------|---------------|--------|" >> $GITHUB_STEP_SUMMARY
            
            echo "$CACHES" | jq -r '.actions_caches[] | [.key, (.size_in_bytes / 1048576 | floor | tostring + " MB"), .created_at[:10], .last_accessed_at[:10], .ref] | @tsv' | while IFS=$'\t' read -r key size created accessed ref; do
              # Truncate long keys
              if [ ${#key} -gt 50 ]; then
                key="${key:0:47}..."
              fi
              echo "| $key | $size | $created | $accessed | $ref |" >> $GITHUB_STEP_SUMMARY
            done
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Identify optimization opportunities
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "## ðŸ’¡ Optimization Opportunities" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          CACHES=$(gh api repos/${{ github.repository }}/actions/caches --paginate 2>/dev/null || echo '{"actions_caches":[]}')
          
          # Find old caches (not accessed in 30+ days)
          OLD_CACHES=$(echo "$CACHES" | jq -r --arg date "$(date -d '30 days ago' +%Y-%m-%d 2>/dev/null || date -v-30d +%Y-%m-%d)" '.actions_caches[] | select(.last_accessed_at < $date) | .key' 2>/dev/null || echo "")
          OLD_COUNT=$(echo "$OLD_CACHES" | grep -c . 2>/dev/null || echo "0")
          
          # Find large caches (1GB+)
          LARGE_CACHES=$(echo "$CACHES" | jq -r '.actions_caches[] | select(.size_in_bytes > 1073741824) | "\(.key): \(.size_in_bytes / 1073741824 | . * 100 | floor / 100) GB"')
          LARGE_COUNT=$(echo "$LARGE_CACHES" | grep -c . 2>/dev/null || echo "0")
          
          if [ "$OLD_COUNT" -gt 0 ]; then
            echo "### ðŸ• Old Caches (Not accessed in 30+ days)" >> $GITHUB_STEP_SUMMARY
            echo "These caches may be candidates for cleanup:" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "$OLD_CACHES" | head -10 >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -n "$LARGE_CACHES" ] && [ "$LARGE_COUNT" -gt 0 ]; then
            echo "### ðŸ“¦ Large Caches (1 GB+)" >> $GITHUB_STEP_SUMMARY
            echo "With new larger limits, these are now supported!" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "$LARGE_CACHES" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "$OLD_COUNT" -eq 0 ] && [ "$LARGE_COUNT" -eq 0 ]; then
            echo "âœ… No obvious optimization opportunities found." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Cleanup old caches
        if: inputs.action == 'cleanup-old'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DAYS_OLD: ${{ inputs.days_old }}
        run: |
          echo "## ðŸ§¹ Cleanup: Old Caches" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          CUTOFF_DATE=$(date -d "${DAYS_OLD} days ago" +%Y-%m-%d 2>/dev/null || date -v-${DAYS_OLD}d +%Y-%m-%d)
          echo "Deleting caches not accessed since: $CUTOFF_DATE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          CACHES=$(gh api repos/${{ github.repository }}/actions/caches --paginate 2>/dev/null)
          
          DELETED=0
          echo "$CACHES" | jq -r --arg date "$CUTOFF_DATE" '.actions_caches[] | select(.last_accessed_at < $date) | "\(.id)|\(.key)"' | while IFS='|' read -r id key; do
            echo "Deleting: $key"
            gh api -X DELETE repos/${{ github.repository }}/actions/caches/$id 2>/dev/null && DELETED=$((DELETED + 1))
          done
          
          echo "âœ… Cleanup complete." >> $GITHUB_STEP_SUMMARY

      - name: Cleanup oversized caches
        if: inputs.action == 'cleanup-oversized'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SIZE_LIMIT_GB: ${{ inputs.size_limit_gb }}
        run: |
          echo "## ðŸ§¹ Cleanup: Oversized Caches" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          SIZE_LIMIT_BYTES=$(echo "$SIZE_LIMIT_GB * 1073741824" | bc)
          echo "Deleting caches larger than: ${SIZE_LIMIT_GB} GB" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          CACHES=$(gh api repos/${{ github.repository }}/actions/caches --paginate 2>/dev/null)
          
          echo "$CACHES" | jq -r --argjson limit "$SIZE_LIMIT_BYTES" '.actions_caches[] | select(.size_in_bytes > $limit) | "\(.id)|\(.key)|\(.size_in_bytes / 1073741824 | . * 100 | floor / 100)"' | while IFS='|' read -r id key size; do
            echo "Deleting: $key (${size} GB)"
            gh api -X DELETE repos/${{ github.repository }}/actions/caches/$id 2>/dev/null
          done
          
          echo "âœ… Cleanup complete." >> $GITHUB_STEP_SUMMARY
